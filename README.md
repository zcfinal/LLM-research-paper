# LLM-research-paper
paper list about large language model (LLM)

## LLM Evaluation

1. "Is ChatGPT a General-Purpose Natural Language Processing Task Solver?"
    Arxiv (2023).
    [[paper](https://arxiv.org/abs/2302.06476)] <br />
    Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, Diyi Yang
  
2. "A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity"
    Arxiv (2023).
    [[paper](https://arxiv.org/abs/2302.04023)] <br />
    Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, Pascale Fung
    
## Efficient Tuning

1. "VL-Adapter: Parameter-Efficient Transfer Learning for Vision-and-Language Tasks"
    CVPR (2022).
    [[paper](https://arxiv.org/abs/2112.06825)] <br />
    Yi-Lin Sung, Jaemin Cho, Mohit Bansal

2. "Multimodal Few-Shot Learning with Frozen Language Models"
    NIPS (2021).
    [[paper](https://proceedings.neurips.cc/paper/2021/file/01b7575c38dac42f3cfb7d500438b875-Paper.pdf)] <br />
    Maria Tsimpoukelli, Jacob L Menick, Serkan Cabi, S. M. Ali Eslami, Oriol Vinyals, Felix Hill
    

3. "Modular and Parameter-Efficient Multimodal Fusion with Prompting"
    Findings of ACL (2022).
    [[paper](https://aclanthology.org/2022.findings-acl.234/)] <br />
    Sheng Liang, Mengjie Zhao, Hinrich Schuetze

4. "Learning to prompt for vision-language models"
    IJCV (2022).
    [[paper](https://arxiv.org/pdf/2109.01134.pdf)] <br />
    Kaiyang Zhou, Jingkang Yang, Chen Change Loy, Ziwei Liu 
    
5. "Conditional prompt learning for vision-language models"
    CVPR (2022).
    [[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Conditional_Prompt_Learning_for_Vision-Language_Models_CVPR_2022_paper.pdf)] <br />
    Kaiyang Zhou, Jingkang Yang, Chen Change Loy, Ziwei Liu
    
6. "Maple: Multi-modal prompt learning"
    Arxiv (2022).
    [[paper](https://arxiv.org/pdf/2210.03117.pdf)] <br />
    Muhammad Uzair Khattak, Hanoona Rasheed, Muhammad Maaz, Salman Khan, Fahad Shahbaz Khan

## LLM with Multimodal 

1. See, Think, Confirm: Interactive Prompting Between Vision and Language Models for Knowledge-based Visual Reasoning

2. Multimodal Chain-of-Thought Reasoning in Language Models

3. Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering

4. Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners

5. An empirical study of gpt-3 for few-shot knowledge-based vqa

6. KAT: A Knowledge Augmented Transformer for Vision-and-Language

7. REVIVE: Regional Visual Representation Matters in Knowledge-Based Visual Question Answering

8. DECAP: DECODING CLIP LATENTS FOR ZERO-SHOT CAPTIONING VIA TEXT-ONLY TRAINING

9. 


